{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this demo is to showcase a scenario in which an hypothetical bank wants to build an AI system to support decision-making regarding credit concession to potential clients. The AI system should be trustable, hence they want to use TrustML to assess the trustworthiness of the candidate classification models before their deployment.\n",
    "\n",
    "We use the Statlog dataset to simulate the scenario and the TrustML package to verify the model's trustworthiness.\n",
    "\n",
    "# Step 1: Defining the configuration file\n",
    "In this scenario, the company is interested in having an AI model complying with several trustworthiness criteria. In decreasing order of importance for the bank, the AI system should comply with:\n",
    "1. Performance: It is worse to class a customer as good when they are bad, than it is to class a customer as bad when they are good.\n",
    "2. Uncertainty: Knowing how uncertain the prediction is might influence the banker to (not) assume the risks.\n",
    "3. Explainability: The bank will need models that provide explanations to the bankers, in order to enable the comprehension of how the AI system predicts the credit risk.\n",
    "4. Fairness: Ethical aspects for the bank to prevent scandal. Protected attributes: gender, age.\n",
    "\n",
    "Based on this criteria, we define an appropiate configuration file accounting for the trustworthiness definition and the weights of the metrics and associated dimensions. We will use the weighted average assessment method.\n",
    "\n",
    "This is the content of the configuration file we will use:\n",
    "```yaml\n",
    "metrics:\n",
    "    - AccuracySKL\n",
    "    - PrecisionSKL:\n",
    "        multiclass_average: \"binary\"\n",
    "    - RecallSKL:\n",
    "        multiclass_average: \"binary\"\n",
    "    - PPercentageSKL:\n",
    "        protected_attributes: [statussex_A91,statussex_A92,statussex_A93,statussex_A94]\n",
    "        positive_class: 1\n",
    "    - EqualOpportunitySKL:\n",
    "        protected_attributes: [statussex_A91,statussex_A92,statussex_A93,statussex_A94]\n",
    "        positive_class: 1\n",
    "    - FaithfulnessLIMESKL:\n",
    "        explainer_path: \"demos/german_credit/lime_explainer\"\n",
    "    - InvertedExpectedCalibrationSKL\n",
    "    - InvertedBrierSKL\n",
    "assessment_method:\n",
    "    WeightedAverage:\n",
    "        performance-0.4:\n",
    "            AccuracySKL: 0.1\n",
    "            PrecisionSKL: 0.2\n",
    "            RecallSKL: 0.7\n",
    "        uncertainty-0.3:                  \n",
    "            InvertedBrierSKL: 0.5\n",
    "            InvertedExpectedCalibrationSKL: 0.5\n",
    "        explainability-0.2:                \n",
    "            FaithfulnessLIMESKL: 1\n",
    "        fairness-0.1:             \n",
    "            PPercentageSKL: 0.5\n",
    "            EqualOpportunitySKL: 0.5\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Import relevant packages\n",
    "The first step will consist in importing the TrustML package, the classification model that we will use in the demo (RandomForestClassifier) and some supporting functions/modules, notably pandas for the dataset loading/manipulation, LimeTabularExplainer to train and evaluate an explainer for the model, and train_test_split to partition the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from dill import dump\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import pandas as pd\n",
    "from trustML.computation import TrustComputation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We force pandas to print every column of the dataset when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.reset_option(\"max_columns\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Preliminar operations\n",
    "We define the dataset header, as it is not present in the actual dataset's CSV.\n",
    "\n",
    "We also specify which is the target ('classification' column), and we classify each feature according to its type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_path = 'demos/german_credit/'\n",
    "file_dataset = demo_path + 'german.data'\n",
    "path_configuration_bank = demo_path + 'config_german_credit_banker_corporate.yml'\n",
    "\n",
    "# DATASET HEADER\n",
    "header = ['existingchecking', 'duration', 'credithistory', 'purpose', 'creditamount', \n",
    "         'savings', 'employmentsince', 'installmentrate', 'statussex', 'otherdebtors', \n",
    "         'residencesince', 'property', 'age', 'otherinstallmentplans', 'housing', \n",
    "         'existingcredits', 'job', 'peopleliable', 'telephone', 'foreignworker', 'classification']\n",
    "label_column = 'classification'\n",
    "\n",
    "numerical_variables = ['duration', 'creditamount', 'installmentrate', 'residencesince', 'age', 'existingcredits', 'peopleliable', 'classification']\n",
    "categorical_variables = ['existingchecking', 'credithistory', 'purpose', 'savings', 'employmentsince',\n",
    "           'statussex', 'otherdebtors', 'property', 'otherinstallmentplans', 'housing', 'job', \n",
    "           'telephone', 'foreignworker']\n",
    "\n",
    "# protected_variables = ['statussex_A91', 'statussex_A92', 'statussex_A93', 'statussex_A94']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Load dataset and create train/test splits\n",
    "Now we load the CSV file and perform some basic preprocessing, like replacing the target column's values from [1,2] -> [1,0] for interpretability purposes, and encoding the categorical features into dummy variables to ensure the classification model will be able to be trained on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET LOAD\n",
    "pd_dataset = pd.read_csv(file_dataset, names=header, delimiter= ' ')\n",
    "pd_dataset.head(10)\n",
    "\n",
    "# CLASSIFICATION COLUMN. [1,2] -> [1,0]\n",
    "pd_dataset.classification.replace([1,2], [1,0], inplace=True)\n",
    "pd_dataset.classification.value_counts()\n",
    "\n",
    "# LABEL ENCODING FOR CATEGORICAL/ORDINAL FEATURES\n",
    "pd_dataset = pd.get_dummies(pd_dataset)\n",
    "#print(pd_dataset.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will split the dataset into training and test, with a 70%-30% proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN-TEST SPLIT\n",
    "# SPLIT FEATURES-TARGET (X-Y)\n",
    "data_x = pd_dataset.drop(label_column, axis=1)\n",
    "data_y = pd_dataset[label_column]\n",
    "# SPLIT DATA\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Create and train the classifier\n",
    "We will now train a random forest classifier on the training set, as well as a lime tabular explainer that will be able to provide prediction's explanations based on the random forest's output. This explainer will be also assessed for trustworthiness as part of the explainability-related metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN A RANDOM FOREST CLASSIFIER AND CREATE A TABULAR EXPLAINER\n",
    "rf_classifier = RandomForestClassifier(max_depth=10, n_estimators=100,criterion='gini')\n",
    "rf_model = rf_classifier.fit(train_x, train_y)\n",
    "lime_explainer = LimeTabularExplainer(train_x.values, feature_names=data_x.columns.values, class_names=[1,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Store required assets\n",
    "The explainability-related metric *FaithfulnessLIMESKL* requires an additional properties, a LIME tabular explainer. Therefore, we will store such asset into the directory we have set in the configuration file. The \"explainer_path\" property corresponds to the previously fitted lime tabular explainer. We store it using dill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE EXPLAINER TO THE DEMO DIRECTORY (OPTIONAL, ONLY NECESSARY IF IT IS NOT ALREADY PRESENT)\n",
    "with open(demo_path + 'lime_explainer', 'wb') as explainer_file:\n",
    "    dump(lime_explainer, explainer_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Compute the trustworthiness\n",
    "Once trained, we will assess its trustworthiness with the TrustML package. For this, we instantiate a TrustComputation, we call the load_trust_definition method with the path to the configuration file we specified, and lastly we call the compute_trust function, passing the trained model and the test dataset (features and target) to evaluate the model's trustworthiness in such dataset. This function stores the trust assessment as a JSON-formatted string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_german_credit = TrustComputation()\n",
    "trust_german_credit.load_trust_definition(config_path=path_configuration_bank)\n",
    "trust_german_credit.compute_trust(trained_model=rf_model, data_x=test_x, data_y=test_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can print the complete trustworthiness assessment as a JSON-formatted string using the getTrustworthinessScore function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trust_german_credit.get_trust_as_JSON())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```javascript\n",
    "{\n",
    "    \"name\": \"Trust\",\n",
    "    \"weighted_score\": 0.75,\n",
    "    \"children\": [{\n",
    "            \"name\": \"performance\",\n",
    "            \"weight\": 0.4,\n",
    "            \"weighted_score\": 0.35,\n",
    "            \"raw_score\": 0.89,\n",
    "            \"children\": [{\n",
    "                    \"name\": \"AccuracySKL\",\n",
    "                    \"weight\": 0.1,\n",
    "                    \"weighted_score\": 0.08,\n",
    "                    \"raw_score\": 0.75\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"PrecisionSKL\",\n",
    "                    \"weight\": 0.2,\n",
    "                    \"weighted_score\": 0.15,\n",
    "                    \"raw_score\": 0.75\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"RecallSKL\",\n",
    "                    \"weight\": 0.7,\n",
    "                    \"weighted_score\": 0.66,\n",
    "                    \"raw_score\": 0.95\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"uncertainty\",\n",
    "            \"weight\": 0.3,\n",
    "            \"weighted_score\": 0.2,\n",
    "            \"raw_score\": 0.67,\n",
    "            \"children\": [{\n",
    "                    \"name\": \"InvertedBrierSKL\",\n",
    "                    \"weight\": 0.5,\n",
    "                    \"weighted_score\": 0.18,\n",
    "                    \"raw_score\": 0.36\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"InvertedExpectedCalibrationSKL\",\n",
    "                    \"weight\": 0.5,\n",
    "                    \"weighted_score\": 0.48,\n",
    "                    \"raw_score\": 0.97\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"explainability\",\n",
    "            \"weight\": 0.2,\n",
    "            \"weighted_score\": 0.11,\n",
    "            \"raw_score\": 0.53,\n",
    "            \"children\": [{\n",
    "                \"name\": \"FaithfulnessLIMESKL\",\n",
    "                \"weight\": 1,\n",
    "                \"weighted_score\": 0.53,\n",
    "                \"raw_score\": 0.53\n",
    "            }]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fairness\",\n",
    "            \"weight\": 0.1,\n",
    "            \"weighted_score\": 0.09,\n",
    "            \"raw_score\": 0.93,\n",
    "            \"children\": [{\n",
    "                    \"name\": \"PPercentageSKL\",\n",
    "                    \"weight\": 0.5,\n",
    "                    \"weighted_score\": 0.45,\n",
    "                    \"raw_score\": 0.91\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"EqualOpportunitySKL\",\n",
    "                    \"weight\": 0.5,\n",
    "                    \"weighted_score\": 0.48,\n",
    "                    \"raw_score\": 0.96\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "Which results in a value of 0.75 of the trustworthiness indicator for the classification model that will conform the AI system.\n",
    "\n",
    "This notebook has illustrated how easy it is to use the TrustML package to evaluate the trustworthiness of a classification model intended to be used as part of an AI system. In this case, the TrustML package has been used as part of a model building pipeline, obtaining a trustworthiness assessment of 0.75 (out of 1). According to the trustability criteria of the ficticious company, the model would not deemed as acceptable, as their threshold is 0.9. Therefore, the model/training data would require modifications aiming to improve the overall trustworthiness of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env4ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9717086da0a9af0457c47e23af3ec726ed6d43f3f34da84c0887679a92baa5a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
