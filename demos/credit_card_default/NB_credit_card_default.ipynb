{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this demo is to showcase a scenario in which a ficticious bank wants to implement an ML-based AI system to predict the likelihood that an applicant will default on a credit-card loan. It could be used, in part, to determine whether a client is eligible for another loan or a credit increase. The AI system should be trustable, hence they want to use TrustML to assess the trustworthiness of the candidate classification models before their deployment.\n",
    "\n",
    "We use the \"credit card default\" dataset (https://www.kaggle.com/datasets/uciml/default-of-credit-card-clients-dataset), which contains historical data on credit-card defaults in Taiwan to simulate the scenario and the TrustML package to verify the model's trustworthiness.\n",
    "\n",
    "# Step 1: Defining the configuration file\n",
    "In this scenario, the bank is interested in having an AI model complying with several trustworthiness criteria. In decreasing order of importance for them, the AI system should comply with:\n",
    "1. Performance. It is worse to class customers as low default risk when they are actually of high default risk, than it is to class customers as high risk when they are actually of low default risk.\n",
    "2. Uncertainty. Knowing how uncertain the prediction is, as itâ€™s important for the banker in order to increase the credit or giving new loans. More uncertainty, more risk for the banker.\n",
    "3. Fairness. Ethical aspects. Sensiblel attributes from the applicants: gender. The AI system should perform the predictions regardless of the sensible attributes.\n",
    "\n",
    "Based on this, we specify a configuration file based on metrics belonging to the three considered trustworthiness dimensions, and we specify the assessment method as a weighted average with equal weights for the two dimensions and the metrics that will be used.\n",
    "\n",
    "We define the configuration file as follows:\n",
    "\n",
    "```yaml\n",
    "metrics:\n",
    "    - AccuracySKL\n",
    "    - PrecisionSKL:\n",
    "        multiclass_average: \"binary\"\n",
    "    - RecallSKL:\n",
    "        multiclass_average: \"binary\"\n",
    "    - F1SKL:\n",
    "        multiclass_average: \"binary\"\n",
    "    - PPercentageSKL:\n",
    "        protected_attributes: [SEX]\n",
    "        positive_class: 0\n",
    "    - EqualOpportunitySKL:\n",
    "        protected_attributes: [SEX]\n",
    "        positive_class: 0    \n",
    "    - InvertedExpectedCalibrationSKL\n",
    "    - InvertedBrierSKL\n",
    "assessment_method:\n",
    "    WeightedAverage:\n",
    "        performance-0.3:\n",
    "            AccuracySKL: 0.1\n",
    "            PrecisionSKL: 0.1\n",
    "            RecallSKL: 0.6\n",
    "            F1SKL: 0.2\n",
    "        uncertainty-0.4:                  \n",
    "            InvertedBrierSKL: 0.5\n",
    "            InvertedExpectedCalibrationSKL: 0.5        \n",
    "        fairness-0.3:             \n",
    "            PPercentageSKL: 0.5\n",
    "            EqualOpportunitySKL: 0.5\n",
    "```\n",
    "\n",
    "Note how we included the sensible attribute in the fairness-related metrics (SEX column), as well as the positive target, which is \"0\" in this case, i.e., the positive target is no credit-card default, while \"1\" indicates the credit-hard holder defaulted."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Import relevant packages\n",
    "The first step will consist in importing the TrustML package, the classification model that we will use in the demo (RandomForestClassifier) and some supporting functions/modules, notably pandas for the dataset loading/manipulation and train_test_split to partition the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from trustML.computation import TrustComputation\n",
    "\n",
    "pd.reset_option(\"max_columns\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Load dataset and create train/test splits\n",
    "Now we load the dataset file, and we do some preprocessing: we drop the irrelevant \"ID\" feature, we set the type of the categorical features to pandas' \"category\", and extract the target column (i.e., if the credit card holder defaulted or not), and split the dataset into training and test, with a 70%-30% proportion.\n",
    "\n",
    "NOTE that pandas will require the \"xlrd\" package to read the dataset file, as it is in Excel format.\n",
    "\n",
    "We can install it easily through pip:\n",
    "```\n",
    "pip install xlrd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_path = 'demos/credit_card_default/'\n",
    "file_dataset = demo_path + 'credit_card_default.xls'\n",
    "path_configuration_bank = demo_path + 'config_credit_card_default.yml'\n",
    "\n",
    "# Load the data\n",
    "dataset = pd.read_excel(file_dataset, header=1).drop(columns=['ID']).rename(columns={'PAY_0':'PAY_1'})\n",
    "dataset.head()\n",
    "\n",
    "# Extract the target\n",
    "Y = dataset[\"default payment next month\"]\n",
    "categorical_features = ['EDUCATION', 'MARRIAGE','PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "for col in categorical_features:\n",
    "    dataset[col] = dataset[col].astype('category')\n",
    "\n",
    "# SENSITIVE COLUMN [2 (female), 1 (male)] -> [0,1]\n",
    "dataset['SEX'].replace([2,1], [0,1], inplace=True)\n",
    "\n",
    "# Decompose the dataset\n",
    "# Train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset.drop(columns=['default payment next month']), \n",
    "    Y, test_size = 0.3, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Create and train the classifier\n",
    "We will now train a random forest classifier on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN A RANDOM FOREST CLASSIFIER\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Compute the trustworthiness\n",
    "Once trained, we will assess its trustworthiness with the TrustML package. For this, we instantiate a TrustComputation, we call the load_trust_definition method with the path to the configuration file we specified, and lastly we call the compute_trust function, passing the trained model and the test dataset (features and target) to evaluate the model's trustworthiness in such dataset. This function stores the trust assessment as a JSON-formatted string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRUST STUFF\n",
    "trust_bank = TrustComputation()\n",
    "trust_bank.load_trust_definition(config_path=path_configuration_bank)\n",
    "trust_bank.compute_trust(trained_model=rf_classifier, data_x=X_test, data_y=Y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can print the complete trustworthiness assessment as a JSON-formatted string using the get_trust_as_JSON function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trust_bank.get_trust_as_JSON())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which results in the following output:\n",
    "\n",
    "```javascript\n",
    "{\n",
    "  \"name\": \"Trust\",\n",
    "  \"weighted_score\": 0.68,\n",
    "  \"children\": [\n",
    "    {\n",
    "      \"name\": \"performance\",\n",
    "      \"weight\": 0.3,\n",
    "      \"weighted_score\": 0.14,\n",
    "      \"raw_score\": 0.45,\n",
    "      \"children\": [\n",
    "        {\n",
    "          \"name\": \"AccuracySKL\",\n",
    "          \"weight\": 0.1,\n",
    "          \"weighted_score\": 0.08,\n",
    "          \"raw_score\": 0.81\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"PrecisionSKL\",\n",
    "          \"weight\": 0.1,\n",
    "          \"weighted_score\": 0.06,\n",
    "          \"raw_score\": 0.65\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"RecallSKL\",\n",
    "          \"weight\": 0.6,\n",
    "          \"weighted_score\": 0.21,\n",
    "          \"raw_score\": 0.36\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"F1SKL\",\n",
    "          \"weight\": 0.2,\n",
    "          \"weighted_score\": 0.09,\n",
    "          \"raw_score\": 0.46\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"uncertainty\",\n",
    "      \"weight\": 0.4,\n",
    "      \"weighted_score\": 0.25,\n",
    "      \"raw_score\": 0.63,\n",
    "      \"children\": [\n",
    "        {\n",
    "          \"name\": \"InvertedBrierSKL\",\n",
    "          \"weight\": 0.5,\n",
    "          \"weighted_score\": 0.14,\n",
    "          \"raw_score\": 0.27\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"InvertedExpectedCalibrationSKL\",\n",
    "          \"weight\": 0.5,\n",
    "          \"weighted_score\": 0.5,\n",
    "          \"raw_score\": 0.99\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"fairness\",\n",
    "      \"weight\": 0.3,\n",
    "      \"weighted_score\": 0.29,\n",
    "      \"raw_score\": 0.97,\n",
    "      \"children\": [\n",
    "        {\n",
    "          \"name\": \"PPercentageSKL\",\n",
    "          \"weight\": 0.5,\n",
    "          \"weighted_score\": 0.48,\n",
    "          \"raw_score\": 0.96\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"EqualOpportunitySKL\",\n",
    "          \"weight\": 0.5,\n",
    "          \"weighted_score\": 0.49,\n",
    "          \"raw_score\": 0.98\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate a graphical report in PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_bank.generate_trust_PDF(save_path=demo_path + \"report_german_credit.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which would generate a PDF an excerpt of which is shown in the following image:\n",
    "\n",
    "![Report excerpt](excerpt_report.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Conclusions\n",
    "Which results in a value of 0.68 of the trustworthiness indicator for the classification model that will conform the AI system. As we can observe in the drill-down assessment, despite the considerably high accuracy (0.81), partly due to the class-imbalance, the low recall and F1 scores negatively impact the overall performance dimension and thus the Trustworthiness of the model. \n",
    "\n",
    "According to the trustability criteria of the ficticious open source community, the model would not be deemed as acceptable, as the recall obtained is low (raw score of 0.36, weighted score of 0.21) and the overall trustworthiness obtained is below their threshold (0.8), so the model/dataset would require changes before the AI system may be deployed and used to assist the bankers' decision making processes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has illustrated how easy it is to use the TrustML package to evaluate the trustworthiness of a classification model intended to be used as part of an AI system. In this case, the TrustML package has been used as part of a model building pipeline, obtaining a trustworthiness assessment of 0.68 (out of 1)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env4ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9717086da0a9af0457c47e23af3ec726ed6d43f3f34da84c0887679a92baa5a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
