<p align="center"><img src="https://user-images.githubusercontent.com/7520973/216668027-e968c4a8-a7e4-486a-8347-c4d2ae637ab1.png"></p>

_trustAI_ is a modular and extensible package to support the definition, assessment and monitoring of custom-built trustworthiness indicators for AI models. _TrustAI_ allows data scientists to define trustworthiness indicators by selecting a set of metrics from a catalog of trustworthy-related metrics and grouping them into higher-level metric aggregations.

_trustAI_ also provides different assessment methods to compute and monitor the indicators previously defined. _trustAI_ enables and supports the development of trustworthy AI models, aiming to provide assistance not only during their construction phase, but also in production environments, as a mechanism to continuously monitor such trust and enable mitigation activities when required.

The package makes use of existing packages meant to compute each of the included trustworthiness metrics, check the requirements.txt file in the root of the source code repository for details.

The API documentation is available on https://martimanzano.github.io/trustAI/.
The wiki with tutorials on the package's usage and extension is available on https://github.com/martimanzano/trustAI/wiki/Home/.

The _trustAI_ package is free software distributed under the Apache License 2.0. If you are interested in participating in this project, please use the [GitHub repository](https://github.com/martimanzano/trustAI); all contributions are welcomed.