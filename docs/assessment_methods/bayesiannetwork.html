<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>trustML.assessment_methods.bayesiannetwork API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>trustML.assessment_methods.bayesiannetwork</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import requests
from trustML.assessment_methods.assessmentmethod import AssessmentMethod
from json import dumps

class BayesianNetwork(AssessmentMethod):
    &#34;&#34;&#34;Class that implements the trust assessment using a Bayesian network in DNE format,
    by using a BN model previously crafted and provided in the filepath specified in the
    configuration file. It requires to have the trust metrics already computed in the trust object.

    It also requires an active and listening server with the SSI-Assessment API-library 
    deployed (https://github.com/martimanzano/SSI-assessment). Its endpoint shall be 
    specified in the configuration file.
    &#34;&#34;&#34;

    def __init__(self, additional_properties):
        &#34;&#34;&#34;Retrieves the set of parameters required to perform the assessment through a BN
        (including the BN filepath and discretization intervals) from the additional properties
        retrieved from the configuration file and prepares the instance&#39;s attributes to perform
        the trustworthiness assessment using the SSI assessment library.

        Args:
            additional_properties (dict): [dictionary of parameters required by the assessment method,
            i.e., the BN&#39;s filepath, endpoint of the assessment service, 
            the BN node corresponding to the trustworthiness, and the discretization intervals to use]
        
        Raises:
            Exception: When assessed metrics and BN&#39;s binning intervals are not consistent
        &#34;&#34;&#34;

        super().__init__()

        self.BN_path = additional_properties[&#39;bn_path&#39;]
        self.API_assessment_service = additional_properties[&#39;api_url&#39;]
        self.id_trust_node = additional_properties[&#39;id_trust_node&#39;]

        self.input_nodes = additional_properties[&#39;intervals_input_nodes&#39;]        
       
    def assess(self):
        &#34;&#34;&#34;Calls the BN assessment service synchrounously to assess the BN node with name equal to the 
        &#34;id_trust_node&#34; attribute. Returns the result as a JSON formatted string containing the node&#39;s 
        probabilitiies.
        &#34;&#34;&#34;

        input_names = [k for d in self.input_nodes for k in d.keys()]
        intervals_input_nodes = [k for d in self.input_nodes for k in d.values()]

        if not self.compare_config_assesssed_metrics_inputs(input_names):
            raise Exception(&#34;Validation error in config file: assessed metrics and BN&#39;s input binning intervals mismatch&#34;)

        input_values = []
        for input_name in input_names:
            input_values.append(self.trust.get_metrics_assessment_dict()[input_name])
                   
        api_response = requests.post(url=self.API_assessment_service, 
        json={&#39;id_si&#39;: self.id_trust_node, &#39;input_names&#39;: input_names,&#39;input_values&#39;: input_values, &#39;intervals_input_nodes&#39;: intervals_input_nodes, &#39;bn_path&#39;: self.BN_path})
        
        assessment_dict = api_response.json() 
        assessment_JSON = dumps(assessment_dict)

        return assessment_dict, assessment_JSON

    def compare_config_assesssed_metrics_inputs(self, inputNames):
        &#34;&#34;&#34;Helper function to validate the binning intervals from the configuration dict.

        Returns:
            Boolean: True if binning intervals are consistent with the assessed metrics, False otherwise
        &#34;&#34;&#34;
        assessed_metrics_list = [metric.__class__.__name__ for metric in self.trust.metrics]
    
        if set(inputNames).issubset(set(assessed_metrics_list)):
            return True
        return False
    
    def generate_trust_PDF(self, save_path):
        &#34;&#34;&#34;Generates a PDF containing the graphical representation of the trustworthiness assessment
        with drill-down to the assessed metrics.

        First traverses the JSON assessment to collect all the data to be plotted in the lists
        &#34;states_names&#34;, &#34;element_names&#34; and &#34;probabilities&#34;. Then it iterates through every element
        and generates a PDF page with a stacked bar chart.

        Args:
            save_path (str): filepath to the PDF to generate
        &#34;&#34;&#34;
        import matplotlib.pyplot as plt
        import numpy as np
        from matplotlib.backends.backend_pdf import PdfPages

        state_names = []
        element_names = []
        probabilities = []
        
        def traverse_hierarchy(element):
            # Extract metric name
            element_name = element[&#39;siname&#39;]
            element_names.append(element_name)

            # Extract states and probabilities
            states = []
            probs = []
            for state_prob in element[&#39;probsSICategories&#39;]:
                state = state_prob[&#39;idSICategory&#39;]
                probability = state_prob[&#39;probSICategory&#39;]
                states.append(state)
                probs.append(probability)

            state_names.append(states)
            probabilities.append(probs)
            
            # Traverse the &#34;parentNodes&#34; list recursively
            if &#39;parentNodes&#39; in element:
                for parent in element[&#39;parentNodes&#39;]:
                    traverse_hierarchy(parent)

        # Start recursive traversal from the top-level element
        data = self.trust.trust_dict
        traverse_hierarchy(data)

        # Set up the plot
        # Plot each element in a separate plot
        with PdfPages(save_path) as pdf:
            for i, element_name in enumerate(element_names):
                fig, ax = plt.subplots(figsize=(2, 5))

                # Set up the plot
                num_states = len(state_names[i])
                ind = np.arange(1)
                width = 0.2

                # Plot the stacked bar
                bottom = 0
                for j in range(num_states):
                    prob = probabilities[i][j]
                    ax.bar(ind, prob, width, bottom=bottom, label=state_names[i][j])
                    bottom += prob

                # Customize the plot
                fig.suptitle(&#39;Trustworthiness assessment - Bayesian Network&#39;, fontsize=16)

                ax.set_ylabel(&#39;Probability&#39;)
                ax.set_title(&#34;Element: &#34; + element_name)
                ax.set_xticks([])
                ax.legend(title=&#39;States&#39;, bbox_to_anchor=(1.05, 1))

                # to switch off the horizontal axis
                frame1 = fig.gca()
                frame1.axes.get_xaxis().set_visible(False)

                pdf.savefig(fig, bbox_inches=&#39;tight&#39;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="trustML.assessment_methods.bayesiannetwork.BayesianNetwork"><code class="flex name class">
<span>class <span class="ident">BayesianNetwork</span></span>
<span>(</span><span>additional_properties)</span>
</code></dt>
<dd>
<div class="desc"><p>Class that implements the trust assessment using a Bayesian network in DNE format,
by using a BN model previously crafted and provided in the filepath specified in the
configuration file. It requires to have the trust metrics already computed in the trust object.</p>
<p>It also requires an active and listening server with the SSI-Assessment API-library
deployed (<a href="https://github.com/martimanzano/SSI-assessment">https://github.com/martimanzano/SSI-assessment</a>). Its endpoint shall be
specified in the configuration file.</p>
<p>Retrieves the set of parameters required to perform the assessment through a BN
(including the BN filepath and discretization intervals) from the additional properties
retrieved from the configuration file and prepares the instance's attributes to perform
the trustworthiness assessment using the SSI assessment library.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>additional_properties</code></strong> :&ensp;<code>dict</code></dt>
<dd>[dictionary of parameters required by the assessment method,</dd>
</dl>
<p>i.e., the BN's filepath, endpoint of the assessment service,
the BN node corresponding to the trustworthiness, and the discretization intervals to use]</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>When assessed metrics and BN's binning intervals are not consistent</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BayesianNetwork(AssessmentMethod):
    &#34;&#34;&#34;Class that implements the trust assessment using a Bayesian network in DNE format,
    by using a BN model previously crafted and provided in the filepath specified in the
    configuration file. It requires to have the trust metrics already computed in the trust object.

    It also requires an active and listening server with the SSI-Assessment API-library 
    deployed (https://github.com/martimanzano/SSI-assessment). Its endpoint shall be 
    specified in the configuration file.
    &#34;&#34;&#34;

    def __init__(self, additional_properties):
        &#34;&#34;&#34;Retrieves the set of parameters required to perform the assessment through a BN
        (including the BN filepath and discretization intervals) from the additional properties
        retrieved from the configuration file and prepares the instance&#39;s attributes to perform
        the trustworthiness assessment using the SSI assessment library.

        Args:
            additional_properties (dict): [dictionary of parameters required by the assessment method,
            i.e., the BN&#39;s filepath, endpoint of the assessment service, 
            the BN node corresponding to the trustworthiness, and the discretization intervals to use]
        
        Raises:
            Exception: When assessed metrics and BN&#39;s binning intervals are not consistent
        &#34;&#34;&#34;

        super().__init__()

        self.BN_path = additional_properties[&#39;bn_path&#39;]
        self.API_assessment_service = additional_properties[&#39;api_url&#39;]
        self.id_trust_node = additional_properties[&#39;id_trust_node&#39;]

        self.input_nodes = additional_properties[&#39;intervals_input_nodes&#39;]        
       
    def assess(self):
        &#34;&#34;&#34;Calls the BN assessment service synchrounously to assess the BN node with name equal to the 
        &#34;id_trust_node&#34; attribute. Returns the result as a JSON formatted string containing the node&#39;s 
        probabilitiies.
        &#34;&#34;&#34;

        input_names = [k for d in self.input_nodes for k in d.keys()]
        intervals_input_nodes = [k for d in self.input_nodes for k in d.values()]

        if not self.compare_config_assesssed_metrics_inputs(input_names):
            raise Exception(&#34;Validation error in config file: assessed metrics and BN&#39;s input binning intervals mismatch&#34;)

        input_values = []
        for input_name in input_names:
            input_values.append(self.trust.get_metrics_assessment_dict()[input_name])
                   
        api_response = requests.post(url=self.API_assessment_service, 
        json={&#39;id_si&#39;: self.id_trust_node, &#39;input_names&#39;: input_names,&#39;input_values&#39;: input_values, &#39;intervals_input_nodes&#39;: intervals_input_nodes, &#39;bn_path&#39;: self.BN_path})
        
        assessment_dict = api_response.json() 
        assessment_JSON = dumps(assessment_dict)

        return assessment_dict, assessment_JSON

    def compare_config_assesssed_metrics_inputs(self, inputNames):
        &#34;&#34;&#34;Helper function to validate the binning intervals from the configuration dict.

        Returns:
            Boolean: True if binning intervals are consistent with the assessed metrics, False otherwise
        &#34;&#34;&#34;
        assessed_metrics_list = [metric.__class__.__name__ for metric in self.trust.metrics]
    
        if set(inputNames).issubset(set(assessed_metrics_list)):
            return True
        return False
    
    def generate_trust_PDF(self, save_path):
        &#34;&#34;&#34;Generates a PDF containing the graphical representation of the trustworthiness assessment
        with drill-down to the assessed metrics.

        First traverses the JSON assessment to collect all the data to be plotted in the lists
        &#34;states_names&#34;, &#34;element_names&#34; and &#34;probabilities&#34;. Then it iterates through every element
        and generates a PDF page with a stacked bar chart.

        Args:
            save_path (str): filepath to the PDF to generate
        &#34;&#34;&#34;
        import matplotlib.pyplot as plt
        import numpy as np
        from matplotlib.backends.backend_pdf import PdfPages

        state_names = []
        element_names = []
        probabilities = []
        
        def traverse_hierarchy(element):
            # Extract metric name
            element_name = element[&#39;siname&#39;]
            element_names.append(element_name)

            # Extract states and probabilities
            states = []
            probs = []
            for state_prob in element[&#39;probsSICategories&#39;]:
                state = state_prob[&#39;idSICategory&#39;]
                probability = state_prob[&#39;probSICategory&#39;]
                states.append(state)
                probs.append(probability)

            state_names.append(states)
            probabilities.append(probs)
            
            # Traverse the &#34;parentNodes&#34; list recursively
            if &#39;parentNodes&#39; in element:
                for parent in element[&#39;parentNodes&#39;]:
                    traverse_hierarchy(parent)

        # Start recursive traversal from the top-level element
        data = self.trust.trust_dict
        traverse_hierarchy(data)

        # Set up the plot
        # Plot each element in a separate plot
        with PdfPages(save_path) as pdf:
            for i, element_name in enumerate(element_names):
                fig, ax = plt.subplots(figsize=(2, 5))

                # Set up the plot
                num_states = len(state_names[i])
                ind = np.arange(1)
                width = 0.2

                # Plot the stacked bar
                bottom = 0
                for j in range(num_states):
                    prob = probabilities[i][j]
                    ax.bar(ind, prob, width, bottom=bottom, label=state_names[i][j])
                    bottom += prob

                # Customize the plot
                fig.suptitle(&#39;Trustworthiness assessment - Bayesian Network&#39;, fontsize=16)

                ax.set_ylabel(&#39;Probability&#39;)
                ax.set_title(&#34;Element: &#34; + element_name)
                ax.set_xticks([])
                ax.legend(title=&#39;States&#39;, bbox_to_anchor=(1.05, 1))

                # to switch off the horizontal axis
                frame1 = fig.gca()
                frame1.axes.get_xaxis().set_visible(False)

                pdf.savefig(fig, bbox_inches=&#39;tight&#39;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="trustML.assessment_methods.assessmentmethod.AssessmentMethod" href="assessmentmethod.html#trustML.assessment_methods.assessmentmethod.AssessmentMethod">AssessmentMethod</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="trustML.assessment_methods.bayesiannetwork.BayesianNetwork.assess"><code class="name flex">
<span>def <span class="ident">assess</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Calls the BN assessment service synchrounously to assess the BN node with name equal to the
"id_trust_node" attribute. Returns the result as a JSON formatted string containing the node's
probabilitiies.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assess(self):
    &#34;&#34;&#34;Calls the BN assessment service synchrounously to assess the BN node with name equal to the 
    &#34;id_trust_node&#34; attribute. Returns the result as a JSON formatted string containing the node&#39;s 
    probabilitiies.
    &#34;&#34;&#34;

    input_names = [k for d in self.input_nodes for k in d.keys()]
    intervals_input_nodes = [k for d in self.input_nodes for k in d.values()]

    if not self.compare_config_assesssed_metrics_inputs(input_names):
        raise Exception(&#34;Validation error in config file: assessed metrics and BN&#39;s input binning intervals mismatch&#34;)

    input_values = []
    for input_name in input_names:
        input_values.append(self.trust.get_metrics_assessment_dict()[input_name])
               
    api_response = requests.post(url=self.API_assessment_service, 
    json={&#39;id_si&#39;: self.id_trust_node, &#39;input_names&#39;: input_names,&#39;input_values&#39;: input_values, &#39;intervals_input_nodes&#39;: intervals_input_nodes, &#39;bn_path&#39;: self.BN_path})
    
    assessment_dict = api_response.json() 
    assessment_JSON = dumps(assessment_dict)

    return assessment_dict, assessment_JSON</code></pre>
</details>
</dd>
<dt id="trustML.assessment_methods.bayesiannetwork.BayesianNetwork.compare_config_assesssed_metrics_inputs"><code class="name flex">
<span>def <span class="ident">compare_config_assesssed_metrics_inputs</span></span>(<span>self, inputNames)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper function to validate the binning intervals from the configuration dict.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Boolean</code></dt>
<dd>True if binning intervals are consistent with the assessed metrics, False otherwise</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compare_config_assesssed_metrics_inputs(self, inputNames):
    &#34;&#34;&#34;Helper function to validate the binning intervals from the configuration dict.

    Returns:
        Boolean: True if binning intervals are consistent with the assessed metrics, False otherwise
    &#34;&#34;&#34;
    assessed_metrics_list = [metric.__class__.__name__ for metric in self.trust.metrics]

    if set(inputNames).issubset(set(assessed_metrics_list)):
        return True
    return False</code></pre>
</details>
</dd>
<dt id="trustML.assessment_methods.bayesiannetwork.BayesianNetwork.generate_trust_PDF"><code class="name flex">
<span>def <span class="ident">generate_trust_PDF</span></span>(<span>self, save_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a PDF containing the graphical representation of the trustworthiness assessment
with drill-down to the assessed metrics.</p>
<p>First traverses the JSON assessment to collect all the data to be plotted in the lists
"states_names", "element_names" and "probabilities". Then it iterates through every element
and generates a PDF page with a stacked bar chart.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>save_path</code></strong> :&ensp;<code>str</code></dt>
<dd>filepath to the PDF to generate</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_trust_PDF(self, save_path):
    &#34;&#34;&#34;Generates a PDF containing the graphical representation of the trustworthiness assessment
    with drill-down to the assessed metrics.

    First traverses the JSON assessment to collect all the data to be plotted in the lists
    &#34;states_names&#34;, &#34;element_names&#34; and &#34;probabilities&#34;. Then it iterates through every element
    and generates a PDF page with a stacked bar chart.

    Args:
        save_path (str): filepath to the PDF to generate
    &#34;&#34;&#34;
    import matplotlib.pyplot as plt
    import numpy as np
    from matplotlib.backends.backend_pdf import PdfPages

    state_names = []
    element_names = []
    probabilities = []
    
    def traverse_hierarchy(element):
        # Extract metric name
        element_name = element[&#39;siname&#39;]
        element_names.append(element_name)

        # Extract states and probabilities
        states = []
        probs = []
        for state_prob in element[&#39;probsSICategories&#39;]:
            state = state_prob[&#39;idSICategory&#39;]
            probability = state_prob[&#39;probSICategory&#39;]
            states.append(state)
            probs.append(probability)

        state_names.append(states)
        probabilities.append(probs)
        
        # Traverse the &#34;parentNodes&#34; list recursively
        if &#39;parentNodes&#39; in element:
            for parent in element[&#39;parentNodes&#39;]:
                traverse_hierarchy(parent)

    # Start recursive traversal from the top-level element
    data = self.trust.trust_dict
    traverse_hierarchy(data)

    # Set up the plot
    # Plot each element in a separate plot
    with PdfPages(save_path) as pdf:
        for i, element_name in enumerate(element_names):
            fig, ax = plt.subplots(figsize=(2, 5))

            # Set up the plot
            num_states = len(state_names[i])
            ind = np.arange(1)
            width = 0.2

            # Plot the stacked bar
            bottom = 0
            for j in range(num_states):
                prob = probabilities[i][j]
                ax.bar(ind, prob, width, bottom=bottom, label=state_names[i][j])
                bottom += prob

            # Customize the plot
            fig.suptitle(&#39;Trustworthiness assessment - Bayesian Network&#39;, fontsize=16)

            ax.set_ylabel(&#39;Probability&#39;)
            ax.set_title(&#34;Element: &#34; + element_name)
            ax.set_xticks([])
            ax.legend(title=&#39;States&#39;, bbox_to_anchor=(1.05, 1))

            # to switch off the horizontal axis
            frame1 = fig.gca()
            frame1.axes.get_xaxis().set_visible(False)

            pdf.savefig(fig, bbox_inches=&#39;tight&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="trustML.assessment_methods" href="index.html">trustML.assessment_methods</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="trustML.assessment_methods.bayesiannetwork.BayesianNetwork" href="#trustML.assessment_methods.bayesiannetwork.BayesianNetwork">BayesianNetwork</a></code></h4>
<ul class="">
<li><code><a title="trustML.assessment_methods.bayesiannetwork.BayesianNetwork.assess" href="#trustML.assessment_methods.bayesiannetwork.BayesianNetwork.assess">assess</a></code></li>
<li><code><a title="trustML.assessment_methods.bayesiannetwork.BayesianNetwork.compare_config_assesssed_metrics_inputs" href="#trustML.assessment_methods.bayesiannetwork.BayesianNetwork.compare_config_assesssed_metrics_inputs">compare_config_assesssed_metrics_inputs</a></code></li>
<li><code><a title="trustML.assessment_methods.bayesiannetwork.BayesianNetwork.generate_trust_PDF" href="#trustML.assessment_methods.bayesiannetwork.BayesianNetwork.generate_trust_PDF">generate_trust_PDF</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>